{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11197d44",
   "metadata": {},
   "source": [
    "Building a RAG model with langchain and HUgging face embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4699913",
   "metadata": {},
   "source": [
    "Retrieval Agumented Generation is a powerful technique that combines capabilities of large language models with external knowledge reterival\n",
    "* Langchain :A framework for developing applications powered by language models\n",
    "* Chroma DB: An open source vector database for storing and retrieving embeddings\n",
    "* OpenAI or (hugging face, groq embeddings):for embeddings and language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ec309b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ea44558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "## vector stores\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2398850",
   "metadata": {},
   "source": [
    "### RAG Architecture\n",
    "1. Document Loading : Load documents from various sources\n",
    "2. Document Splitting: Split documents into chunks \n",
    "3. embedding generation: convert chunks into vectors using embedding \n",
    "4. vector storage: store embedding into vector store(chromabd , fiass or vector db)\n",
    "5. query processing : convert user query into embedding \n",
    "6. similarity search: Get the similarity search from vector store to get relevant \n",
    "7. Context Agumentation: combine retrieved chunks with query \n",
    "8. response generation: LLM generates answer using context \n",
    "#### Benefits of using RAG\n",
    "1. reduce hallucinations\n",
    "2. provides up-to-date information\n",
    "3. allows citing sources\n",
    "4. works with domain specific knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ce5a2",
   "metadata": {},
   "source": [
    "#### Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c5e0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "dirload=DirectoryLoader(\n",
    "    'data',\n",
    "    glob='*.txt',\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding':'utf-8'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74d0af20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc1.txt'}, page_content=\"Natural Language Processing (NLP) is a subfield of artificial intelligence that enables computers to understand, interpret, and generate human language in a meaningful way.\\nDefinition and Overview\\nNatural Language Processing (NLP) combines computer science, artificial intelligence, and linguistics to facilitate interactions between computers and humans using natural language. It encompasses a range of techniques that allow machines to process and analyze large amounts of natural language data, enabling them to perform tasks such as translation, sentiment analysis, and text summarization. \\nGeeksForGeeks\\n+1\\nKey Applications\\nNLP is widely used in various applications, including:\\nChatbots and Virtual Assistants: Tools like Amazon's Alexa and Apple's Siri utilize NLP to understand user queries and provide relevant responses. \\n2\\nText Translation: NLP powers translation services that convert text from one language to another while preserving meaning and context. \\n2\\nSentiment Analysis: Businesses use NLP to analyze customer feedback and social media interactions to gauge public sentiment about products or services. \\n1\\nInformation Extraction: NLP techniques help extract relevant information from unstructured data, such as identifying key entities and relationships within text. \\n1\\n\\n\\n4 Sources\\nTechniques in NLP\\nNLP employs various techniques to analyze and manipulate human language, including:\\nTokenization: Breaking down text into smaller units, such as words or phrases, for easier analysis. \\n1\\nPart-of-Speech Tagging: Assigning grammatical categories (e.g., noun, verb) to each word in a sentence. \\n1\\nNamed Entity Recognition: Identifying and classifying key entities (e.g., names, dates) within text. \\n1\\nSentiment Analysis: Determining the emotional tone behind a series of words, often used to understand customer opinions. \\n1\\nText Summarization: Condensing long texts into shorter summaries while retaining essential information. \\n1\"),\n",
       " Document(metadata={'source': 'data\\\\doc2.txt'}, page_content='Large Language Models (LLMs) are advanced AI systems built on deep neural networks designed to process, understand and generate human-like text. By using massive datasets and billions of parameters, LLMs have transformed the way humans interact with technology. It learns patterns, grammar and context from text and can answer questions, write content, translate languages and many more. Mordern LLMs include ChatGPT (OpenAI), Google Gemini, Anthropic Claude, etc\\n\\nexploring_large_language_models_llms_\\nLLM\\nTo explore the technical concepts behind LLMs, understand how they work, what they can do and how to build projects using them, refer to our Large Language Model (LLM) Tutorial.\\n\\nWorking of LLM\\nLLMs are primarily based on the Transformer architecture which enables them to learn long-range dependencies and contextual meaning in text. At a high level, they work through:\\n\\ntransformers_in_llms\\nWorking\\nInput Embeddings: Converting text into numerical vectors.\\nPositional Encoding: Adding sequence/order information.\\nSelf-Attention: Understanding relationships between words in context.\\nFeed-Forward Layers: Capturing complex patterns.\\nDecoding: Generating responses step-by-step.\\nMulti-Head Attention: Parallel reasoning over multiple relationships.\\nTo know more about transformers architecture refer to: Architecture and Working of Transformers in Deep Learning\\n\\nArchitecture\\nThe architecture of LLMs consist of multiple stacked layers that process text in parallel. Core components include:\\n\\nEmbedding Layer: Converts tokens i.e words/subwords into dense vectors.\\nAttention Mechanism: Learns context by focusing on relevant words.\\nFeed-Forward Layers: Capture non-linear patterns and relationships.\\nNormalization and Residual Connections: Improve training stability.\\nOutput Layer: Generates predictions such as the next word or sentence.'),\n",
       " Document(metadata={'source': 'data\\\\doc3.txt'}, page_content='Large Language Models (LLMs) are advanced AI systems built on deep neural networks designed to process, understand and generate human-like text. By using massive datasets and billions of parameters, LLMs have transformed the way humans interact with technology. It learns patterns, grammar and context from text and can answer questions, write content, translate languages and many more. Mordern LLMs include ChatGPT (OpenAI), Google Gemini, Anthropic Claude, etc\\n\\nexploring_large_language_models_llms_\\nLLM\\nTo explore the technical concepts behind LLMs, understand how they work, what they can do and how to build projects using them, refer to our Large Language Model (LLM) Tutorial.\\n\\nWorking of LLM\\nLLMs are primarily based on the Transformer architecture which enables them to learn long-range dependencies and contextual meaning in text. At a high level, they work through:\\n\\ntransformers_in_llms\\nWorking\\nInput Embeddings: Converting text into numerical vectors.\\nPositional Encoding: Adding sequence/order information.\\nSelf-Attention: Understanding relationships between words in context.\\nFeed-Forward Layers: Capturing complex patterns.\\nDecoding: Generating responses step-by-step.\\nMulti-Head Attention: Parallel reasoning over multiple relationships.\\nTo know more about transformers architecture refer to: Architecture and Working of Transformers in Deep Learning\\n\\nArchitecture\\nThe architecture of LLMs consist of multiple stacked layers that process text in parallel. Core components include:\\n\\nEmbedding Layer: Converts tokens i.e words/subwords into dense vectors.\\nAttention Mechanism: Learns context by focusing on relevant words.\\nFeed-Forward Layers: Capture non-linear patterns and relationships.\\nNormalization and Residual Connections: Improve training stability.\\nOutput Layer: Generates predictions such as the next word or sentence.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_txtfiles=dirload.load()\n",
    "loaded_txtfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a70cc",
   "metadata": {},
   "source": [
    "### Splitting files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "396167df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data\\\\doc1.txt'}, page_content='Natural Language Processing (NLP) is a subfield of artificial intelligence that enables computers to understand, interpret, and generate human language in a meaningful way.\\nDefinition and Overview\\nNatural Language Processing (NLP) combines computer science, artificial intelligence, and linguistics to facilitate interactions between computers and humans using natural language. It encompasses a range of techniques that allow machines to process and analyze large amounts of natural language data,'), Document(metadata={'source': 'data\\\\doc1.txt'}, page_content=\"of techniques that allow machines to process and analyze large amounts of natural language data, enabling them to perform tasks such as translation, sentiment analysis, and text summarization. \\nGeeksForGeeks\\n+1\\nKey Applications\\nNLP is widely used in various applications, including:\\nChatbots and Virtual Assistants: Tools like Amazon's Alexa and Apple's Siri utilize NLP to understand user queries and provide relevant responses. \\n2\\nText Translation: NLP powers translation services that convert\"), Document(metadata={'source': 'data\\\\doc1.txt'}, page_content='and provide relevant responses. \\n2\\nText Translation: NLP powers translation services that convert text from one language to another while preserving meaning and context. \\n2\\nSentiment Analysis: Businesses use NLP to analyze customer feedback and social media interactions to gauge public sentiment about products or services. \\n1\\nInformation Extraction: NLP techniques help extract relevant information from unstructured data, such as identifying key entities and relationships within text. \\n1\\n\\n\\n4'), Document(metadata={'source': 'data\\\\doc1.txt'}, page_content='from unstructured data, such as identifying key entities and relationships within text. \\n1\\n\\n\\n4 Sources\\nTechniques in NLP\\nNLP employs various techniques to analyze and manipulate human language, including:\\nTokenization: Breaking down text into smaller units, such as words or phrases, for easier analysis. \\n1\\nPart-of-Speech Tagging: Assigning grammatical categories (e.g., noun, verb) to each word in a sentence. \\n1\\nNamed Entity Recognition: Identifying and classifying key entities (e.g., names,'), Document(metadata={'source': 'data\\\\doc1.txt'}, page_content='in a sentence. \\n1\\nNamed Entity Recognition: Identifying and classifying key entities (e.g., names, dates) within text. \\n1\\nSentiment Analysis: Determining the emotional tone behind a series of words, often used to understand customer opinions. \\n1\\nText Summarization: Condensing long texts into shorter summaries while retaining essential information. \\n1'), Document(metadata={'source': 'data\\\\doc2.txt'}, page_content='Large Language Models (LLMs) are advanced AI systems built on deep neural networks designed to process, understand and generate human-like text. By using massive datasets and billions of parameters, LLMs have transformed the way humans interact with technology. It learns patterns, grammar and context from text and can answer questions, write content, translate languages and many more. Mordern LLMs include ChatGPT (OpenAI), Google Gemini, Anthropic Claude,'), Document(metadata={'source': 'data\\\\doc2.txt'}, page_content='languages and many more. Mordern LLMs include ChatGPT (OpenAI), Google Gemini, Anthropic Claude, etc\\n\\nexploring_large_language_models_llms_\\nLLM\\nTo explore the technical concepts behind LLMs, understand how they work, what they can do and how to build projects using them, refer to our Large Language Model (LLM) Tutorial.\\n\\nWorking of LLM\\nLLMs are primarily based on the Transformer architecture which enables them to learn long-range dependencies and contextual meaning in text. At a high level,'), Document(metadata={'source': 'data\\\\doc2.txt'}, page_content='enables them to learn long-range dependencies and contextual meaning in text. At a high level, they work through:\\n\\ntransformers_in_llms\\nWorking\\nInput Embeddings: Converting text into numerical vectors.\\nPositional Encoding: Adding sequence/order information.\\nSelf-Attention: Understanding relationships between words in context.\\nFeed-Forward Layers: Capturing complex patterns.\\nDecoding: Generating responses step-by-step.\\nMulti-Head Attention: Parallel reasoning over multiple relationships.\\nTo know'), Document(metadata={'source': 'data\\\\doc2.txt'}, page_content='step-by-step.\\nMulti-Head Attention: Parallel reasoning over multiple relationships.\\nTo know more about transformers architecture refer to: Architecture and Working of Transformers in Deep Learning\\n\\nArchitecture\\nThe architecture of LLMs consist of multiple stacked layers that process text in parallel. Core components include:\\n\\nEmbedding Layer: Converts tokens i.e words/subwords into dense vectors.\\nAttention Mechanism: Learns context by focusing on relevant words.\\nFeed-Forward Layers: Capture'), Document(metadata={'source': 'data\\\\doc2.txt'}, page_content='Mechanism: Learns context by focusing on relevant words.\\nFeed-Forward Layers: Capture non-linear patterns and relationships.\\nNormalization and Residual Connections: Improve training stability.\\nOutput Layer: Generates predictions such as the next word or sentence.'), Document(metadata={'source': 'data\\\\doc3.txt'}, page_content='Large Language Models (LLMs) are advanced AI systems built on deep neural networks designed to process, understand and generate human-like text. By using massive datasets and billions of parameters, LLMs have transformed the way humans interact with technology. It learns patterns, grammar and context from text and can answer questions, write content, translate languages and many more. Mordern LLMs include ChatGPT (OpenAI), Google Gemini, Anthropic Claude,'), Document(metadata={'source': 'data\\\\doc3.txt'}, page_content='languages and many more. Mordern LLMs include ChatGPT (OpenAI), Google Gemini, Anthropic Claude, etc\\n\\nexploring_large_language_models_llms_\\nLLM\\nTo explore the technical concepts behind LLMs, understand how they work, what they can do and how to build projects using them, refer to our Large Language Model (LLM) Tutorial.\\n\\nWorking of LLM\\nLLMs are primarily based on the Transformer architecture which enables them to learn long-range dependencies and contextual meaning in text. At a high level,'), Document(metadata={'source': 'data\\\\doc3.txt'}, page_content='enables them to learn long-range dependencies and contextual meaning in text. At a high level, they work through:\\n\\ntransformers_in_llms\\nWorking\\nInput Embeddings: Converting text into numerical vectors.\\nPositional Encoding: Adding sequence/order information.\\nSelf-Attention: Understanding relationships between words in context.\\nFeed-Forward Layers: Capturing complex patterns.\\nDecoding: Generating responses step-by-step.\\nMulti-Head Attention: Parallel reasoning over multiple relationships.\\nTo know'), Document(metadata={'source': 'data\\\\doc3.txt'}, page_content='step-by-step.\\nMulti-Head Attention: Parallel reasoning over multiple relationships.\\nTo know more about transformers architecture refer to: Architecture and Working of Transformers in Deep Learning\\n\\nArchitecture\\nThe architecture of LLMs consist of multiple stacked layers that process text in parallel. Core components include:\\n\\nEmbedding Layer: Converts tokens i.e words/subwords into dense vectors.\\nAttention Mechanism: Learns context by focusing on relevant words.\\nFeed-Forward Layers: Capture'), Document(metadata={'source': 'data\\\\doc3.txt'}, page_content='Mechanism: Learns context by focusing on relevant words.\\nFeed-Forward Layers: Capture non-linear patterns and relationships.\\nNormalization and Residual Connections: Improve training stability.\\nOutput Layer: Generates predictions such as the next word or sentence.')]\n",
      "Len of the chunks documents: 15\n",
      "first chunk is page_content='Natural Language Processing (NLP) is a subfield of artificial intelligence that enables computers to understand, interpret, and generate human language in a meaningful way.\n",
      "Definition and Overview\n",
      "Natural Language Processing (NLP) combines computer science, artificial intelligence, and linguistics to facilitate interactions between computers and humans using natural language. It encompasses a range of techniques that allow machines to process and analyze large amounts of natural language data,' metadata={'source': 'data\\\\doc1.txt'}\n",
      "second chunk is page_content='of techniques that allow machines to process and analyze large amounts of natural language data, enabling them to perform tasks such as translation, sentiment analysis, and text summarization. \n",
      "GeeksForGeeks\n",
      "+1\n",
      "Key Applications\n",
      "NLP is widely used in various applications, including:\n",
      "Chatbots and Virtual Assistants: Tools like Amazon's Alexa and Apple's Siri utilize NLP to understand user queries and provide relevant responses. \n",
      "2\n",
      "Text Translation: NLP powers translation services that convert' metadata={'source': 'data\\\\doc1.txt'}\n"
     ]
    }
   ],
   "source": [
    "splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    separators=[\" \"]\n",
    ")\n",
    "chunks=splitter.split_documents(loaded_txtfiles)\n",
    "print(chunks)\n",
    "print(f\"Len of the chunks documents: {len(chunks)}\")\n",
    "print(f\"first chunk is {chunks[0]}\")\n",
    "print(f\"second chunk is {chunks[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc1.txt'}, page_content='Natural Language Processing (NLP) is a subfield of artificial intelligence that enables computers to understand, interpret, and generate human language in a meaningful way.\\nDefinition and Overview\\nNatural Language Processing (NLP) combines computer science, artificial intelligence, and linguistics to facilitate interactions between computers and humans using natural language. It encompasses a range of techniques that allow machines to process and analyze large amounts of natural language data,'),\n",
       " Document(metadata={'source': 'data\\\\doc1.txt'}, page_content=\"of techniques that allow machines to process and analyze large amounts of natural language data, enabling them to perform tasks such as translation, sentiment analysis, and text summarization. \\nGeeksForGeeks\\n+1\\nKey Applications\\nNLP is widely used in various applications, including:\\nChatbots and Virtual Assistants: Tools like Amazon's Alexa and Apple's Siri utilize NLP to understand user queries and provide relevant responses. \\n2\\nText Translation: NLP powers translation services that convert\"),\n",
       " Document(metadata={'source': 'data\\\\doc1.txt'}, page_content='and provide relevant responses. \\n2\\nText Translation: NLP powers translation services that convert text from one language to another while preserving meaning and context. \\n2\\nSentiment Analysis: Businesses use NLP to analyze customer feedback and social media interactions to gauge public sentiment about products or services. \\n1\\nInformation Extraction: NLP techniques help extract relevant information from unstructured data, such as identifying key entities and relationships within text. \\n1\\n\\n\\n4'),\n",
       " Document(metadata={'source': 'data\\\\doc1.txt'}, page_content='from unstructured data, such as identifying key entities and relationships within text. \\n1\\n\\n\\n4 Sources\\nTechniques in NLP\\nNLP employs various techniques to analyze and manipulate human language, including:\\nTokenization: Breaking down text into smaller units, such as words or phrases, for easier analysis. \\n1\\nPart-of-Speech Tagging: Assigning grammatical categories (e.g., noun, verb) to each word in a sentence. \\n1\\nNamed Entity Recognition: Identifying and classifying key entities (e.g., names,'),\n",
       " Document(metadata={'source': 'data\\\\doc1.txt'}, page_content='in a sentence. \\n1\\nNamed Entity Recognition: Identifying and classifying key entities (e.g., names, dates) within text. \\n1\\nSentiment Analysis: Determining the emotional tone behind a series of words, often used to understand customer opinions. \\n1\\nText Summarization: Condensing long texts into shorter summaries while retaining essential information. \\n1'),\n",
       " Document(metadata={'source': 'data\\\\doc2.txt'}, page_content='Large Language Models (LLMs) are advanced AI systems built on deep neural networks designed to process, understand and generate human-like text. By using massive datasets and billions of parameters, LLMs have transformed the way humans interact with technology. It learns patterns, grammar and context from text and can answer questions, write content, translate languages and many more. Mordern LLMs include ChatGPT (OpenAI), Google Gemini, Anthropic Claude,'),\n",
       " Document(metadata={'source': 'data\\\\doc2.txt'}, page_content='languages and many more. Mordern LLMs include ChatGPT (OpenAI), Google Gemini, Anthropic Claude, etc\\n\\nexploring_large_language_models_llms_\\nLLM\\nTo explore the technical concepts behind LLMs, understand how they work, what they can do and how to build projects using them, refer to our Large Language Model (LLM) Tutorial.\\n\\nWorking of LLM\\nLLMs are primarily based on the Transformer architecture which enables them to learn long-range dependencies and contextual meaning in text. At a high level,'),\n",
       " Document(metadata={'source': 'data\\\\doc2.txt'}, page_content='enables them to learn long-range dependencies and contextual meaning in text. At a high level, they work through:\\n\\ntransformers_in_llms\\nWorking\\nInput Embeddings: Converting text into numerical vectors.\\nPositional Encoding: Adding sequence/order information.\\nSelf-Attention: Understanding relationships between words in context.\\nFeed-Forward Layers: Capturing complex patterns.\\nDecoding: Generating responses step-by-step.\\nMulti-Head Attention: Parallel reasoning over multiple relationships.\\nTo know'),\n",
       " Document(metadata={'source': 'data\\\\doc2.txt'}, page_content='step-by-step.\\nMulti-Head Attention: Parallel reasoning over multiple relationships.\\nTo know more about transformers architecture refer to: Architecture and Working of Transformers in Deep Learning\\n\\nArchitecture\\nThe architecture of LLMs consist of multiple stacked layers that process text in parallel. Core components include:\\n\\nEmbedding Layer: Converts tokens i.e words/subwords into dense vectors.\\nAttention Mechanism: Learns context by focusing on relevant words.\\nFeed-Forward Layers: Capture'),\n",
       " Document(metadata={'source': 'data\\\\doc2.txt'}, page_content='Mechanism: Learns context by focusing on relevant words.\\nFeed-Forward Layers: Capture non-linear patterns and relationships.\\nNormalization and Residual Connections: Improve training stability.\\nOutput Layer: Generates predictions such as the next word or sentence.'),\n",
       " Document(metadata={'source': 'data\\\\doc3.txt'}, page_content='Large Language Models (LLMs) are advanced AI systems built on deep neural networks designed to process, understand and generate human-like text. By using massive datasets and billions of parameters, LLMs have transformed the way humans interact with technology. It learns patterns, grammar and context from text and can answer questions, write content, translate languages and many more. Mordern LLMs include ChatGPT (OpenAI), Google Gemini, Anthropic Claude,'),\n",
       " Document(metadata={'source': 'data\\\\doc3.txt'}, page_content='languages and many more. Mordern LLMs include ChatGPT (OpenAI), Google Gemini, Anthropic Claude, etc\\n\\nexploring_large_language_models_llms_\\nLLM\\nTo explore the technical concepts behind LLMs, understand how they work, what they can do and how to build projects using them, refer to our Large Language Model (LLM) Tutorial.\\n\\nWorking of LLM\\nLLMs are primarily based on the Transformer architecture which enables them to learn long-range dependencies and contextual meaning in text. At a high level,'),\n",
       " Document(metadata={'source': 'data\\\\doc3.txt'}, page_content='enables them to learn long-range dependencies and contextual meaning in text. At a high level, they work through:\\n\\ntransformers_in_llms\\nWorking\\nInput Embeddings: Converting text into numerical vectors.\\nPositional Encoding: Adding sequence/order information.\\nSelf-Attention: Understanding relationships between words in context.\\nFeed-Forward Layers: Capturing complex patterns.\\nDecoding: Generating responses step-by-step.\\nMulti-Head Attention: Parallel reasoning over multiple relationships.\\nTo know'),\n",
       " Document(metadata={'source': 'data\\\\doc3.txt'}, page_content='step-by-step.\\nMulti-Head Attention: Parallel reasoning over multiple relationships.\\nTo know more about transformers architecture refer to: Architecture and Working of Transformers in Deep Learning\\n\\nArchitecture\\nThe architecture of LLMs consist of multiple stacked layers that process text in parallel. Core components include:\\n\\nEmbedding Layer: Converts tokens i.e words/subwords into dense vectors.\\nAttention Mechanism: Learns context by focusing on relevant words.\\nFeed-Forward Layers: Capture'),\n",
       " Document(metadata={'source': 'data\\\\doc3.txt'}, page_content='Mechanism: Learns context by focusing on relevant words.\\nFeed-Forward Layers: Capture non-linear patterns and relationships.\\nNormalization and Residual Connections: Improve training stability.\\nOutput Layer: Generates predictions such as the next word or sentence.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d94d1c",
   "metadata": {},
   "source": [
    "### Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings=HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "400c3c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors=embeddings.embed_query(chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c897c199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.009500443935394287,\n",
       " -0.0006951941759325564,\n",
       " 0.06901475787162781,\n",
       " -0.027056686580181122,\n",
       " 0.04192333668470383,\n",
       " -0.02050250954926014,\n",
       " 0.040943603962659836,\n",
       " 0.017849715426564217,\n",
       " -0.008673853240907192,\n",
       " 0.025633497163653374,\n",
       " -0.02867620438337326,\n",
       " -0.051815662533044815,\n",
       " -0.01270467508584261,\n",
       " 0.0034350890200585127,\n",
       " 0.044689711183309555,\n",
       " 0.09272845089435577,\n",
       " -0.004294833168387413,\n",
       " -0.04311579093337059,\n",
       " -0.0594249963760376,\n",
       " -0.03851087763905525,\n",
       " 0.03274223208427429,\n",
       " 0.10735950618982315,\n",
       " -0.08523678034543991,\n",
       " -0.029469335451722145,\n",
       " 0.02170873060822487,\n",
       " 0.09952089935541153,\n",
       " -5.500652696355246e-05,\n",
       " -0.06273727118968964,\n",
       " 0.06564243882894516,\n",
       " 0.0396789088845253,\n",
       " 0.03626876324415207,\n",
       " 0.005678847897797823,\n",
       " 0.04797719791531563,\n",
       " 0.12220264971256256,\n",
       " -0.031764645129442215,\n",
       " 0.062304284423589706,\n",
       " -0.03304588794708252,\n",
       " 0.01355755515396595,\n",
       " -0.01349285151809454,\n",
       " -0.020101826637983322,\n",
       " -0.06572545319795609,\n",
       " -0.05165945366024971,\n",
       " -0.06078336015343666,\n",
       " 0.018244214355945587,\n",
       " 0.1265716701745987,\n",
       " 0.045019570738077164,\n",
       " -0.10442255437374115,\n",
       " 0.04900412634015083,\n",
       " -0.0556442029774189,\n",
       " 0.012169764377176762,\n",
       " -0.12635785341262817,\n",
       " 0.04064913094043732,\n",
       " 0.03035796619951725,\n",
       " 0.09571649134159088,\n",
       " -0.0599510595202446,\n",
       " 0.04763498157262802,\n",
       " 0.008274544030427933,\n",
       " -0.06286543607711792,\n",
       " -0.01757972687482834,\n",
       " -0.08433975279331207,\n",
       " 0.006960858590900898,\n",
       " -0.05767901614308357,\n",
       " 0.006590234115719795,\n",
       " 0.03747903183102608,\n",
       " 0.023705976083874702,\n",
       " 0.02915162406861782,\n",
       " -0.045732446014881134,\n",
       " -0.015154298394918442,\n",
       " 0.04232150316238403,\n",
       " -0.03340444713830948,\n",
       " -0.00828587543219328,\n",
       " 0.08555399626493454,\n",
       " 0.02779809758067131,\n",
       " 0.07486268132925034,\n",
       " -0.06558021903038025,\n",
       " -0.019979780539870262,\n",
       " -0.012879149056971073,\n",
       " -0.05516185611486435,\n",
       " 0.07686394453048706,\n",
       " -0.029835624620318413,\n",
       " 0.021148039028048515,\n",
       " 0.057108715176582336,\n",
       " 0.0627676323056221,\n",
       " 0.06927848607301712,\n",
       " 0.057312265038490295,\n",
       " -0.05224299803376198,\n",
       " 0.018425658345222473,\n",
       " -0.00702039897441864,\n",
       " -0.07259245216846466,\n",
       " 0.028976118192076683,\n",
       " -0.05689771845936775,\n",
       " -0.1023099347949028,\n",
       " 0.059738852083683014,\n",
       " -0.00743662565946579,\n",
       " -0.03163956105709076,\n",
       " 0.06906265765428543,\n",
       " -0.04969730228185654,\n",
       " -0.10647979378700256,\n",
       " 0.04702086001634598,\n",
       " -0.0016223766142502427,\n",
       " 0.029215609654784203,\n",
       " 0.06040991470217705,\n",
       " -0.013409405946731567,\n",
       " -0.07006339728832245,\n",
       " -0.06287581473588943,\n",
       " -0.007372853811830282,\n",
       " -0.02983502298593521,\n",
       " -0.03185425326228142,\n",
       " 0.01905371993780136,\n",
       " -0.10683118551969528,\n",
       " -0.025395940989255905,\n",
       " 0.002066356362774968,\n",
       " -0.035974230617284775,\n",
       " 0.006978037767112255,\n",
       " 0.0502646341919899,\n",
       " -0.019395485520362854,\n",
       " 0.022765114903450012,\n",
       " 0.017322467640042305,\n",
       " 0.04813271760940552,\n",
       " 0.04257288575172424,\n",
       " -0.10140424966812134,\n",
       " 0.033398713916540146,\n",
       " -0.04089808091521263,\n",
       " 0.029870156198740005,\n",
       " 0.008886385709047318,\n",
       " -0.03785614296793938,\n",
       " 0.0928715318441391,\n",
       " 3.763352510997246e-34,\n",
       " -0.034743208438158035,\n",
       " -0.040308672934770584,\n",
       " -0.04482840374112129,\n",
       " -0.04774393513798714,\n",
       " 0.05376053601503372,\n",
       " -0.03213699534535408,\n",
       " -0.039559256285429,\n",
       " -0.01621965505182743,\n",
       " -0.060946669429540634,\n",
       " -0.012861399911344051,\n",
       " 0.02388903684914112,\n",
       " -0.03314804285764694,\n",
       " 0.003453838871791959,\n",
       " 0.00968121737241745,\n",
       " 0.03699267655611038,\n",
       " 0.03565731272101402,\n",
       " -0.07788432389497757,\n",
       " 0.07199874520301819,\n",
       " 0.0316942036151886,\n",
       " 0.004461586009711027,\n",
       " -0.05967891961336136,\n",
       " 0.07661806046962738,\n",
       " 0.012344729155302048,\n",
       " 0.02750411070883274,\n",
       " -0.03037680685520172,\n",
       " 0.047701820731163025,\n",
       " -0.03938450291752815,\n",
       " -0.04512643814086914,\n",
       " 0.015453421510756016,\n",
       " -0.02045557089149952,\n",
       " 0.025110241025686264,\n",
       " 0.08983034640550613,\n",
       " -0.06094390153884888,\n",
       " 0.003047131933271885,\n",
       " -0.0010302887530997396,\n",
       " -0.08268330991268158,\n",
       " 0.04078307002782822,\n",
       " -0.012156524695456028,\n",
       " -0.009885176084935665,\n",
       " -0.02795683592557907,\n",
       " -0.08023437112569809,\n",
       " 0.05082660913467407,\n",
       " 0.005564456339925528,\n",
       " 0.0527837797999382,\n",
       " -0.008055100217461586,\n",
       " 0.03545532375574112,\n",
       " -0.06464719772338867,\n",
       " -0.03150288760662079,\n",
       " 0.025049079209566116,\n",
       " -0.011239930056035519,\n",
       " 0.07672259211540222,\n",
       " 0.0061949980445206165,\n",
       " 0.0024589435197412968,\n",
       " 0.016709504649043083,\n",
       " 0.11332467943429947,\n",
       " 0.005420193541795015,\n",
       " -0.015698473900556564,\n",
       " -0.009587873704731464,\n",
       " 0.02426505833864212,\n",
       " 0.02221963182091713,\n",
       " 0.0652238205075264,\n",
       " -0.007595125585794449,\n",
       " 0.030482377856969833,\n",
       " 0.007807821035385132,\n",
       " 0.022712066769599915,\n",
       " -0.02347862347960472,\n",
       " 0.07831157743930817,\n",
       " -0.0025180785451084375,\n",
       " 0.08056827634572983,\n",
       " -0.00862800981849432,\n",
       " -0.0347726084291935,\n",
       " 0.04153772071003914,\n",
       " 0.019705692306160927,\n",
       " 0.06025154888629913,\n",
       " 0.03706151619553566,\n",
       " 0.005576237570494413,\n",
       " 0.06936155259609222,\n",
       " -0.049897145479917526,\n",
       " -0.02585632912814617,\n",
       " 0.1179024949669838,\n",
       " -0.07414071261882782,\n",
       " -0.10919187217950821,\n",
       " 0.031973209232091904,\n",
       " -0.06650802493095398,\n",
       " 0.02206108160316944,\n",
       " -0.04394127428531647,\n",
       " -0.06309173256158829,\n",
       " 0.027537375688552856,\n",
       " 0.061235785484313965,\n",
       " -0.010966502130031586,\n",
       " -0.01747187413275242,\n",
       " 0.06302569061517715,\n",
       " -0.059309300035238266,\n",
       " 0.06731437146663666,\n",
       " -0.028189435601234436,\n",
       " -1.522834013378065e-33,\n",
       " -0.0644017904996872,\n",
       " -0.010879871435463428,\n",
       " -0.10481543093919754,\n",
       " 0.060582470148801804,\n",
       " -0.027242934331297874,\n",
       " -0.08571582287549973,\n",
       " -0.03853552043437958,\n",
       " -0.030352018773555756,\n",
       " 0.06559939682483673,\n",
       " 0.01283133402466774,\n",
       " 0.004361217841506004,\n",
       " -0.06011081486940384,\n",
       " 0.09619300812482834,\n",
       " 0.05275188758969307,\n",
       " 0.051400329917669296,\n",
       " -0.03152206540107727,\n",
       " -0.010883805342018604,\n",
       " 0.03768737241625786,\n",
       " -0.03933010622859001,\n",
       " 0.0906328558921814,\n",
       " 0.021902628242969513,\n",
       " 0.06713119149208069,\n",
       " -0.08208666741847992,\n",
       " 0.005220548715442419,\n",
       " 0.07018019258975983,\n",
       " 0.02839563600718975,\n",
       " -0.05748148262500763,\n",
       " -0.016786612570285797,\n",
       " -0.023459289222955704,\n",
       " -0.015315663069486618,\n",
       " 0.02129136212170124,\n",
       " 0.01481298916041851,\n",
       " -0.03790494427084923,\n",
       " -0.05089918524026871,\n",
       " 0.02018493227660656,\n",
       " -0.027588950470089912,\n",
       " 0.010413839481770992,\n",
       " -0.011926663108170033,\n",
       " -0.010959320701658726,\n",
       " -0.00741147343069315,\n",
       " 0.08099301159381866,\n",
       " 0.1067582219839096,\n",
       " -0.08023504912853241,\n",
       " -0.028678445145487785,\n",
       " -0.07917539775371552,\n",
       " -0.012339579872786999,\n",
       " -0.07163490355014801,\n",
       " -0.0019334800308570266,\n",
       " 0.009546046145260334,\n",
       " 0.01751270517706871,\n",
       " 0.003824057523161173,\n",
       " -0.026531940326094627,\n",
       " -0.012360719032585621,\n",
       " -0.03345343843102455,\n",
       " -0.031414762139320374,\n",
       " -7.967109559103847e-05,\n",
       " 0.03569915145635605,\n",
       " -0.0691000372171402,\n",
       " -0.061945728957653046,\n",
       " 0.041817810386419296,\n",
       " -0.03498188033699989,\n",
       " 0.026372354477643967,\n",
       " 0.10374682396650314,\n",
       " -0.03353632614016533,\n",
       " 0.031215768307447433,\n",
       " -0.01921907067298889,\n",
       " -0.05742646008729935,\n",
       " 0.048213206231594086,\n",
       " -0.0814950093626976,\n",
       " -0.031071359291672707,\n",
       " 0.03573049604892731,\n",
       " 0.038785990327596664,\n",
       " 0.02321351133286953,\n",
       " 0.10614557564258575,\n",
       " -0.00064441142603755,\n",
       " -0.010625887662172318,\n",
       " 0.00647004647180438,\n",
       " -0.04396142065525055,\n",
       " -0.0340358167886734,\n",
       " -0.0343252494931221,\n",
       " 0.09268146753311157,\n",
       " 0.0280551016330719,\n",
       " 0.05847501382231712,\n",
       " 0.00010921076318481937,\n",
       " -0.028912225738167763,\n",
       " 0.013238543644547462,\n",
       " -0.03842774033546448,\n",
       " 0.008383083157241344,\n",
       " 0.006366348825395107,\n",
       " -0.01323059480637312,\n",
       " 0.025378858670592308,\n",
       " -0.02694232389330864,\n",
       " -0.08341898769140244,\n",
       " 0.10891850292682648,\n",
       " -0.05822424218058586,\n",
       " -3.572640494553525e-08,\n",
       " -0.05787081643939018,\n",
       " -0.04392378404736519,\n",
       " -0.02910587377846241,\n",
       " -0.008510889485478401,\n",
       " 0.014653965830802917,\n",
       " 0.03515979275107384,\n",
       " -0.019022352993488312,\n",
       " 0.01437181606888771,\n",
       " -0.04407531023025513,\n",
       " -0.12287671118974686,\n",
       " 0.0515059232711792,\n",
       " 0.060498520731925964,\n",
       " -0.06395705044269562,\n",
       " -0.03425176814198494,\n",
       " 0.031258463859558105,\n",
       " -0.003979890141636133,\n",
       " 0.032437972724437714,\n",
       " -0.0644577145576477,\n",
       " 0.03704383969306946,\n",
       " -0.047808896750211716,\n",
       " 0.10327477008104324,\n",
       " 0.0035915521439164877,\n",
       " -0.04528416693210602,\n",
       " 0.10708913207054138,\n",
       " 0.019120795652270317,\n",
       " -0.04045398160815239,\n",
       " -0.02696884796023369,\n",
       " 0.020466413348913193,\n",
       " -0.018804533407092094,\n",
       " -0.09555438160896301,\n",
       " 0.022130068391561508,\n",
       " 0.07369469851255417,\n",
       " -0.02519609034061432,\n",
       " 0.06705274432897568,\n",
       " 0.11112447082996368,\n",
       " 0.0561862513422966,\n",
       " -0.011204089038074017,\n",
       " -0.12598282098770142,\n",
       " -0.054711807519197464,\n",
       " -0.05716643109917641,\n",
       " 0.005470568779855967,\n",
       " 0.10437961667776108,\n",
       " -0.07654213905334473,\n",
       " -0.04552377015352249,\n",
       " 0.0646292045712471,\n",
       " -0.022824984043836594,\n",
       " 0.017672691494226456,\n",
       " -0.11463437229394913,\n",
       " 0.023671746253967285,\n",
       " -0.0073487963527441025,\n",
       " -0.012554049491882324,\n",
       " -0.06343384087085724,\n",
       " 0.0025878993328660727,\n",
       " 0.06233746558427811,\n",
       " 0.05680062249302864,\n",
       " -0.025990940630435944,\n",
       " -0.0022177845239639282,\n",
       " 0.004519949201494455,\n",
       " -0.02043679729104042,\n",
       " -0.03415510430932045,\n",
       " -0.06607748568058014,\n",
       " 0.10057125985622406,\n",
       " 0.09002429246902466,\n",
       " 0.0064818598330020905]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed74398c",
   "metadata": {},
   "source": [
    "### Initailize the chromadb vector store and store chunks in vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x2081fc9a210>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persistent_dir=\"./chroma_db\"\n",
    "\n",
    "vector_store=Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=HuggingFaceEmbeddings(),\n",
    "    persist_directory=persistent_dir,\n",
    "    collection_name='RAG_Collection'\n",
    ")\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"What is NLP?\" \n",
    "similar_docs=vector_store.similarity_search(query,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc1.txt'}, page_content='Natural Language Processing (NLP) is a subfield of artificial intelligence that enables computers to understand, interpret, and generate human language in a meaningful way.\\nDefinition and Overview\\nNatural Language Processing (NLP) combines computer science, artificial intelligence, and linguistics to facilitate interactions between computers and humans using natural language. It encompasses a range of techniques that allow machines to process and analyze large amounts of natural language data,'),\n",
       " Document(metadata={'source': 'data\\\\doc1.txt'}, page_content='Natural Language Processing (NLP) is a subfield of artificial intelligence that enables computers to understand, interpret, and generate human language in a meaningful way.\\nDefinition and Overview\\nNatural Language Processing (NLP) combines computer science, artificial intelligence, and linguistics to facilitate interactions between computers and humans using natural language. It encompasses a range of techniques that allow machines to process and analyze large amounts of natural language data,'),\n",
       " Document(metadata={'source': 'data\\\\doc1.txt'}, page_content='Natural Language Processing (NLP) is a subfield of artificial intelligence that enables computers to understand, interpret, and generate human language in a meaningful way.\\nDefinition and Overview\\nNatural Language Processing (NLP) combines computer science, artificial intelligence, and linguistics to facilitate interactions between computers and humans using natural language. It encompasses a range of techniques that allow machines to process and analyze large amounts of natural language data,')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28db9e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data\\\\doc1.txt'}, page_content='Natural Language Processing (NLP) is a subfield of artificial intelligence that enables computers to understand, interpret, and generate human language in a meaningful way.\\nDefinition and Overview\\nNatural Language Processing (NLP) combines computer science, artificial intelligence, and linguistics to facilitate interactions between computers and humans using natural language. It encompasses a range of techniques that allow machines to process and analyze large amounts of natural language data,'),\n",
       "  0.4971999228000641),\n",
       " (Document(metadata={'source': 'data\\\\doc1.txt'}, page_content='Natural Language Processing (NLP) is a subfield of artificial intelligence that enables computers to understand, interpret, and generate human language in a meaningful way.\\nDefinition and Overview\\nNatural Language Processing (NLP) combines computer science, artificial intelligence, and linguistics to facilitate interactions between computers and humans using natural language. It encompasses a range of techniques that allow machines to process and analyze large amounts of natural language data,'),\n",
       "  0.4971999228000641),\n",
       " (Document(metadata={'source': 'data\\\\doc1.txt'}, page_content='Natural Language Processing (NLP) is a subfield of artificial intelligence that enables computers to understand, interpret, and generate human language in a meaningful way.\\nDefinition and Overview\\nNatural Language Processing (NLP) combines computer science, artificial intelligence, and linguistics to facilitate interactions between computers and humans using natural language. It encompasses a range of techniques that allow machines to process and analyze large amounts of natural language data,'),\n",
       "  0.4971999228000641),\n",
       " (Document(metadata={'source': 'data\\\\doc1.txt'}, page_content='Natural Language Processing (NLP) is a subfield of artificial intelligence that enables computers to understand, interpret, and generate human language in a meaningful way.\\nDefinition and Overview\\nNatural Language Processing (NLP) combines computer science, artificial intelligence, and linguistics to facilitate interactions between computers and humans using natural language. It encompasses a range of techniques that allow machines to process and analyze large amounts of natural language data,'),\n",
       "  0.4971999228000641),\n",
       " (Document(metadata={'source': 'data\\\\doc1.txt'}, page_content=\"of techniques that allow machines to process and analyze large amounts of natural language data, enabling them to perform tasks such as translation, sentiment analysis, and text summarization. \\nGeeksForGeeks\\n+1\\nKey Applications\\nNLP is widely used in various applications, including:\\nChatbots and Virtual Assistants: Tools like Amazon's Alexa and Apple's Siri utilize NLP to understand user queries and provide relevant responses. \\n2\\nText Translation: NLP powers translation services that convert\"),\n",
       "  0.8159940242767334),\n",
       " (Document(metadata={'source': 'data\\\\doc1.txt'}, page_content=\"of techniques that allow machines to process and analyze large amounts of natural language data, enabling them to perform tasks such as translation, sentiment analysis, and text summarization. \\nGeeksForGeeks\\n+1\\nKey Applications\\nNLP is widely used in various applications, including:\\nChatbots and Virtual Assistants: Tools like Amazon's Alexa and Apple's Siri utilize NLP to understand user queries and provide relevant responses. \\n2\\nText Translation: NLP powers translation services that convert\"),\n",
       "  0.8159940242767334),\n",
       " (Document(metadata={'source': 'data\\\\doc1.txt'}, page_content=\"of techniques that allow machines to process and analyze large amounts of natural language data, enabling them to perform tasks such as translation, sentiment analysis, and text summarization. \\nGeeksForGeeks\\n+1\\nKey Applications\\nNLP is widely used in various applications, including:\\nChatbots and Virtual Assistants: Tools like Amazon's Alexa and Apple's Siri utilize NLP to understand user queries and provide relevant responses. \\n2\\nText Translation: NLP powers translation services that convert\"),\n",
       "  0.8159940242767334),\n",
       " (Document(metadata={'source': 'data\\\\doc1.txt'}, page_content=\"of techniques that allow machines to process and analyze large amounts of natural language data, enabling them to perform tasks such as translation, sentiment analysis, and text summarization. \\nGeeksForGeeks\\n+1\\nKey Applications\\nNLP is widely used in various applications, including:\\nChatbots and Virtual Assistants: Tools like Amazon's Alexa and Apple's Siri utilize NLP to understand user queries and provide relevant responses. \\n2\\nText Translation: NLP powers translation services that convert\"),\n",
       "  0.8159940242767334)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores=vector_store.similarity_search_with_score(query,k=8)\n",
    "similarity_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d1cee3",
   "metadata": {},
   "source": [
    "* Chroma db uses eculdiean distance , means closer to 0 means similar macth it ranges from 0 to 2 (sometimes even higher)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f776a9b5",
   "metadata": {},
   "source": [
    "### Initialize LLM,RAG Chain,Prompt Template,Query the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5a70abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeHuggingFaceEndpoint(HuggingFaceEndpoint):\n",
    "    def _process_response(self, result):\n",
    "        \"\"\"Normalize HuggingFace response to plain text\"\"\"\n",
    "        if isinstance(result, list):\n",
    "            if len(result) > 0 and isinstance(result[0], dict) and \"generated_text\" in result[0]:\n",
    "                return result[0][\"generated_text\"]\n",
    "            return str(result)\n",
    "        elif isinstance(result, dict):\n",
    "            return result.get(\"generated_text\", str(result))\n",
    "        return str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0cdb84ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatHuggingFace(llm=SafeHuggingFaceEndpoint(repo_id='openai-community/gpt2', repetition_penalty=1.03, stop_sequences=[], server_kwargs={}, model_kwargs={}, model='openai-community/gpt2', client=<InferenceClient(model='openai-community/gpt2', timeout=120)>, async_client=<InferenceClient(model='openai-community/gpt2', timeout=120)>, task='text-generation'), model_id='openai-community/gpt2', model_kwargs={})"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface.chat_models import ChatHuggingFace\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "model=SafeHuggingFaceEndpoint( repo_id=\"openai-community/gpt2\",\n",
    "            task=\"text-generation\",\n",
    "            max_new_tokens=512,\n",
    "            do_sample=False,\n",
    "            repetition_penalty=1.03)\n",
    "chat=ChatHuggingFace(llm=model,verbose=True)\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3be86f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SafeHuggingFaceEndpoint(repo_id='openai-community/gpt2', repetition_penalty=1.03, stop_sequences=[], server_kwargs={}, model_kwargs={}, model='openai-community/gpt2', client=<InferenceClient(model='openai-community/gpt2', timeout=120)>, async_client=<InferenceClient(model='openai-community/gpt2', timeout=120)>, task='text-generation')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9dda5327",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat=ChatHuggingFace(llm=model,verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1267fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\GENAI\\RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model=ChatOpenAI(\n",
    "    model='gpt-3.5-turbo',\n",
    "    api_key='euri-6201748b43fef9b93ecd0aaf1f374303527711988664d4d774f07bcf092275c2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd9850c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'errors': [{'message': 'Route not found'}],\n",
       " 'statusCode': 404,\n",
       " 'message': 'route: /api/v1/euri/chat/completions, errorMsg: Route not found, rayId: ZUmT8WE2nLFCG8HoED',\n",
       " 'success': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer euri-6201748b43fef9b93ecd0aaf1f374303527711988664d4d774f07bcf092275c2\"\n",
    "    }\n",
    "resp=requests.get(\"https://api.euron.one/api/v1/euri/chat/completions\",headers=headers)\n",
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ea7553c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep learning is a specialized subset of machine learning that focuses on building and training neural networks with multiple layersoften called deep neural networksto automatically learn and extract complex patterns and representations from data. \n",
      "\n",
      "In essence, deep learning models mimic the way the human brain processes information, allowing computers to recognize images, understand speech, translate languages, and perform many other tasks that require understanding high-level features. These models consist of interconnected layers of nodes (neurons), where each layer transforms the input data into increasingly abstract and useful representations. Through large amounts of data and computational power, deep learning models can achieve remarkable accuracy in tasks such as image recognition, natural language processing, and more.\n",
      "\n",
      "Key features of deep learning include:\n",
      "- **Multiple layers**: Deep neural networks have many hidden layers that enable learning of intricate patterns.\n",
      "- **Feature learning**: Unlike traditional algorithms that require manual feature extraction, deep learning models automatically learn relevant features from raw data.\n",
      "- **Large datasets and computing power**: Training deep networks typically requires substantial data and high-performance hardware like GPUs.\n",
      "\n",
      "Overall, deep learning has revolutionized many fields by enabling machines to perform tasks that were previously considered extremely challenging for computers.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.outputs import Generation, LLMResult\n",
    "\n",
    "from langchain_core.prompts.base import StringPromptValue\n",
    "from langchain_core.prompts.chat import ChatPromptValue\n",
    "\n",
    "\n",
    "class EuronChatModel(Runnable):\n",
    "    \"\"\"Custom Runnable wrapper for the Euron Chat API (OpenAI-style).\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, model_name: str = \"gpt-4.1-nano\"):\n",
    "        self.api_url = \"https://api.euron.one/api/v1/euri/chat/completions\"\n",
    "        self.api_key = api_key\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def invoke(self, input_text, config=None) -> str:\n",
    "        \"\"\"Invoked by LangChain chains (handles PromptValue objects too).\"\"\"\n",
    "\n",
    "        #  Convert LangChain PromptValue -> string if necessary\n",
    "        if isinstance(input_text, (StringPromptValue, ChatPromptValue)):\n",
    "            input_text = input_text.to_string()\n",
    "        elif not isinstance(input_text, str):\n",
    "            input_text = str(input_text)\n",
    "\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "        }\n",
    "\n",
    "        payload = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": input_text}],\n",
    "            \"max_tokens\": 1000,\n",
    "            \"temperature\": 0.7,\n",
    "        }\n",
    "\n",
    "        response = requests.post(self.api_url, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        return data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "\n",
    "# Initialize your API model\n",
    "llm = EuronChatModel(api_key=\"euri-6201748b43fef9b93ecd0aaf1f374303527711988664d4d774f07bcf092275c2\")\n",
    "print(llm.invoke(\"Explain what deep learning.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import init_chat_model\n",
    "\n",
    "# huggingface=init_chat_model(model=\"deepseek-ai/deepseek-llm-7b-chat\",model_provider=\"huggingface:deepseek-ai/deepseek-llm-7b-chat\",config={\n",
    "#     \"temperature\":0.8,\n",
    "#     \"max_new_tokens\":256\n",
    "# })\n",
    "# huggingface.invoke('What is llm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c24ffa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_huggingface import HuggingFacePipeline\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "# pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "# llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# print(llm.invoke(\"Explain LLM in simple words\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51f3e11",
   "metadata": {},
   "source": [
    "### Modern RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21aef573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_classic.chains.retrieval import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9b0a3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000002081FC9A210>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert vector store to retriever\n",
    "retriever=vector_store.as_retriever(\n",
    "    search_kwargs={\"k\":3}\n",
    ")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "168586df",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a Prompt Template\n",
    "system_prompt=\"\"\"\n",
    "You are an assistant for question answering tasks.\n",
    "Use following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer please say don't know the answer .\n",
    "keep answer concise\n",
    "context: {context}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b42816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",system_prompt),\n",
    "     (\"human\",\"{input}\")]\n",
    ")\n",
    "# dummy_docs = [Document(page_content=\"Deep learning uses neural networks for pattern recognition.\")]\n",
    "\n",
    "# prompt.invoke({\"context\":dummy_docs,\"input\":\"what is nlp\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ab7aa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"\\nYou are an assistant for question answering tasks.\\nUse following pieces of retrieved context to answer the question. \\nIf you don't know the answer please say don't know the answer .\\nkeep answer concise\\ncontext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| <__main__.EuronChatModel object at 0x00000208335187D0>\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a document chain\n",
    "document_chain=create_stuff_documents_chain(\n",
    "    llm=llm,prompt=prompt\n",
    ")\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfefcc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000002081FC9A210>, search_kwargs={'k': 3}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"\\nYou are an assistant for question answering tasks.\\nUse following pieces of retrieved context to answer the question. \\nIf you don't know the answer please say don't know the answer .\\nkeep answer concise\\ncontext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | <__main__.EuronChatModel object at 0x00000208335187D0>\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Final rag chain\n",
    "rag_chain=create_retrieval_chain(\n",
    "    retriever=retriever,\n",
    "    combine_docs_chain=document_chain\n",
    ")\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8201bfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final Answer: NLP, or Natural Language Processing, is a subfield of artificial intelligence that focuses on enabling computers to understand, interpret, and generate human language in a meaningful way. It combines techniques from computer science, AI, and linguistics to facilitate interactions between humans and machines using natural language. NLP involves processing and analyzing large amounts of natural language data to achieve tasks such as language translation, sentiment analysis, speech recognition, and more.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_classic.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "# Initialize your API model\n",
    "llm = EuronChatModel(api_key=\"euri-6201748b43fef9b93ecd0aaf1f374303527711988664d4d774f07bcf092275c2\")\n",
    "\n",
    "# Prompt Template (simple instruction format)\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Use the context below to answer the question concisely.\n",
    "If unsure, say you don't know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{input}\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "# Combine document chain\n",
    "document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Retrieval chain (Chroma retriever)\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever=retriever, \n",
    "    combine_docs_chain=document_chain\n",
    ")\n",
    "\n",
    "# Run\n",
    "response = rag_chain.invoke({\"input\": \"What is NLP? give me more info \"})\n",
    "print(\" Final Answer:\", response.get(\"answer\", response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7677e1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is deep learning?',\n",
       " 'context': [Document(metadata={'source': 'data\\\\doc2.txt'}, page_content='Large Language Models (LLMs) are advanced AI systems built on deep neural networks designed to process, understand and generate human-like text. By using massive datasets and billions of parameters, LLMs have transformed the way humans interact with technology. It learns patterns, grammar and context from text and can answer questions, write content, translate languages and many more. Mordern LLMs include ChatGPT (OpenAI), Google Gemini, Anthropic Claude,'),\n",
       "  Document(metadata={'source': 'data\\\\doc3.txt'}, page_content='Large Language Models (LLMs) are advanced AI systems built on deep neural networks designed to process, understand and generate human-like text. By using massive datasets and billions of parameters, LLMs have transformed the way humans interact with technology. It learns patterns, grammar and context from text and can answer questions, write content, translate languages and many more. Mordern LLMs include ChatGPT (OpenAI), Google Gemini, Anthropic Claude,'),\n",
       "  Document(metadata={'source': 'data\\\\doc3.txt'}, page_content='Large Language Models (LLMs) are advanced AI systems built on deep neural networks designed to process, understand and generate human-like text. By using massive datasets and billions of parameters, LLMs have transformed the way humans interact with technology. It learns patterns, grammar and context from text and can answer questions, write content, translate languages and many more. Mordern LLMs include ChatGPT (OpenAI), Google Gemini, Anthropic Claude,')],\n",
       " 'answer': 'Deep learning is a subset of machine learning that uses deep neural networks to model and understand complex patterns in data, enabling systems like Large Language Models to process and generate human-like text.'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a14c25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "\n",
    "app=FastAPI()\n",
    "\n",
    "app.get(\"/home\")\n",
    "def add(a:int,b:int):\n",
    "    return a+b\n",
    "print(add(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac21351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd4aab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be1e572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e30b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d198c7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebfb28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3269f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae36e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45ce70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca98f1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1cf765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e20dad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b41fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e859c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757d90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b402c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceff9a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
